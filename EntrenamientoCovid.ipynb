{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import YolosImageProcessor, AutoModelForObjectDetection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import  DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-small\", \n",
    "                                                             num_labels=1,\n",
    "                                                             ignore_mismatched_sizes=True)\n",
    "model.to(device)\n",
    "processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-small\")\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Parametros entrenables de la red {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bboxes_to_width_height(data):\n",
    "    \"\"\"\n",
    "    Convierte el formato de los bounding boxes en una lista de diccionarios.\n",
    "    Cambia de [x_min, y_min, x_max, y_max] a [x_min, y_min, width, height].\n",
    "\n",
    "    Args:\n",
    "        data (list): Lista de diccionarios con la clave 'bbox' en formato [x_min, y_min, x_max, y_max].\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de diccionarios con los bounding boxes convertidos.\n",
    "    \"\"\"\n",
    "    for item in data:\n",
    "        x_min, y_min, x_max, y_max = item['bbox']\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        # Actualizar el bounding box al nuevo formato\n",
    "        item['bbox'] = [x_min, y_min, width, height]\n",
    "        item[\"category_id\"] = 0 # el category_id se lo cambie de 1 a 0 porque creo que el modelo interpreta la clase 1 como no objeto\n",
    "    return data\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, json_file, images_dir, processor,transform=None):\n",
    "        with open(json_file, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "        \n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener la información de la imagen\n",
    "        image_data = self.data[idx]\n",
    "        image_id = image_data[\"image_id\"]\n",
    "        image_name = image_data[\"image_name\"]\n",
    "        image_path = os.path.join(self.images_dir, image_name)\n",
    "        \n",
    "        # Cargar la imagen usando PIL\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Obtener las anotaciones\n",
    "        converted_data = convert_bboxes_to_width_height(image_data[\"annotations\"])\n",
    "        annotations = converted_data\n",
    "        \n",
    "        # Transformaciones, si las hay\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        \n",
    "        # Procesar con el processor\n",
    "        inputs = self.processor(images=image, annotations={\"image_id\": image_id, \"annotations\": annotations}, return_tensors=\"pt\")\n",
    "        \n",
    "        return {\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),  # Quitar batch dimension\n",
    "            \"labels\": inputs[\"labels\"][0]\n",
    "        }\n",
    "        \n",
    "def guarda_ckpt(ckptpath, modelo, epoca, opt):\n",
    "    estado_modelo = {'epoch': epoca,\n",
    "                     'model_state_dict': modelo.state_dict(),\n",
    "                     'optimizer_state_dict': opt.state_dict()}\n",
    "    torch.save(estado_modelo, ckptpath)\n",
    "    \n",
    "def carga_ckpt(ckptpath, modelo, opt):\n",
    "    checkpoint = torch.load(ckptpath)\n",
    "    \n",
    "    modelo.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    epoca = checkpoint['epoch']  # Obtener la época en la que se guardó\n",
    "    return epoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(json_file=\"labels.json\", images_dir=\"frames\", processor= processor)\n",
    "# Obtenemos una lista de los índices del dataset\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "# Primero dividimos entre entrenamiento y el resto (validación + prueba)\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ahora dividimos el resto entre validación y prueba\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Crear los datasets con los índices\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "# Crear los DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True , collate_fn=lambda x: {\n",
    "    \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in x]),\n",
    "    \"labels\": [item[\"labels\"] for item in x]  # Lista de diccionarios\n",
    "} )\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: {\n",
    "    \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in x]),\n",
    "    \"labels\": [item[\"labels\"] for item in x]  # Lista de diccionarios\n",
    "})\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: {\n",
    "    \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in x]),\n",
    "    \"labels\": [item[\"labels\"] for item in x]  # Lista de diccionarios\n",
    "})\n",
    "print(len(train_dataset),len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeroExperimento = \"11\"\n",
    "EPOCAS = 15\n",
    "PATH = f'checkpoint/checkpoint{numeroExperimento}.pt'\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "# Scheduler\n",
    "#num_training_steps = len(train_loader) * EPOCAS  # 100 épocas\n",
    "#scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historial = {'perdida_ent': np.zeros(EPOCAS, dtype = np.float32),\n",
    "             'perdida_val': np.zeros(EPOCAS, dtype = np.float32)}\n",
    "\n",
    "perdidaMinima = torch.inf\n",
    "mejorModelo = copy.deepcopy(model)\n",
    "\n",
    "for e in range(EPOCAS):  # Número de épocas\n",
    "    model.train()\n",
    "    trainLoss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        print(f\"Va en la epoca:{e + 1 } , en el lote de entrenamiento: {i} \")\n",
    "        # Mover datos a GPU\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "        optimizer.zero_grad()\n",
    "        # Calcular pérdida\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        trainLoss += loss.item()\n",
    "    \n",
    "    trainLoss /= len(train_loader.dataset)\n",
    "    historial['perdida_ent'][e] = trainLoss\n",
    "    \n",
    "    model.eval()\n",
    "    valLoss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            print(f\"Va en la epoca:{e + 1} , en el lote de validacion: {i} \")\n",
    "            # Mover datos a GPU\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "            \n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            valLoss += loss.item()\n",
    "    \n",
    "    valLoss /= len(val_loader.dataset)\n",
    "    historial['perdida_val'][e] = valLoss\n",
    "    \n",
    "    if historial['perdida_val'][e] < perdidaMinima:\n",
    "        mejorModelo.load_state_dict(model.state_dict())\n",
    "        guarda_ckpt(PATH, model, e, optimizer)\n",
    "        perdidaMinima = historial['perdida_val'][e]\n",
    "        torch.save(mejorModelo.state_dict(), f\"YOLOS_small_mejorModelo_entrenamiento_{numeroExperimento}_covid.pt\")\n",
    "        print(f\"Guardo el mejor modelo en la epoca {e + 1}\")\n",
    "        \n",
    "    print(f\"Epoca {e+1}/{EPOCAS}\")\n",
    "    print(f\"Train Loss de la epoca {e+1}: {trainLoss:.12f}\")\n",
    "    print(f\"Validation Loss de la epoca {e+1}: {valLoss:.12f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"YOLOS_small_entrenamiento_{numeroExperimento}_covid.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historial['perdida_ent'], label='Entrenamiento')\n",
    "plt.plot(historial['perdida_val'], label='Validación')\n",
    "plt.title(f'Perdida para el entrenamiento {numeroExperimento}')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'historial_{numeroExperimento}.pkl', 'wb') as archivo_pickle:\n",
    "    pickle.dump(historial, archivo_pickle)\n",
    "    \n",
    "with open(f'historial_{numeroExperimento}.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# Mostrar el contenido del diccionario\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('YOLOS_entrenamiento_1_covid.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
