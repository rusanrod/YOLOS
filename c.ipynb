{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import YolosImageProcessor, AutoModelForObjectDetection\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import  DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-small\", \n",
    "                                                             num_labels=1,\n",
    "                                                             ignore_mismatched_sizes=True)\n",
    "model.to(device)\n",
    "processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, json_file, images_dir, processor,transform=None):\n",
    "        with open(json_file, 'r') as file:\n",
    "            self.data = json.load(file)\n",
    "        \n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener la información de la imagen\n",
    "        image_data = self.data[idx]\n",
    "        image_id = image_data[\"image_id\"]\n",
    "        image_name = image_data[\"image_name\"]\n",
    "        image_path = os.path.join(self.images_dir, image_name)\n",
    "        \n",
    "        # Cargar la imagen usando PIL\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Obtener las anotaciones\n",
    "        annotations = image_data[\"annotations\"]\n",
    "        \n",
    "        # Transformaciones, si las hay\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        \n",
    "        # Procesar con el processor\n",
    "        inputs = self.processor(images=image, annotations={\"image_id\": image_id, \"annotations\": annotations}, return_tensors=\"pt\")\n",
    "        \n",
    "        return {\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),  # Quitar batch dimension\n",
    "            \"labels\": inputs[\"labels\"][0]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(json_file=\"labels.json\", images_dir=\"frames\", processor= processor)\n",
    "# Obtenemos una lista de los índices del dataset\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "# Primero dividimos entre entrenamiento y el resto (validación + prueba)\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ahora dividimos el resto entre validación y prueba\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Crear los datasets con los índices\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "# Crear los DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,collate_fn=lambda x: {\n",
    "    \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in x]),\n",
    "    \"labels\": [item[\"labels\"] for item in x]  # Lista de diccionarios\n",
    "} )\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: {\n",
    "    \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in x]),\n",
    "    \"labels\": [item[\"labels\"] for item in x]  # Lista de diccionarios\n",
    "})\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: {\n",
    "    \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in x]),\n",
    "    \"labels\": [item[\"labels\"] for item in x]  # Lista de diccionarios\n",
    "})\n",
    "print(len(train_dataset),len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 100\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Scheduler\n",
    "num_training_steps = len(train_loader) * epocas  # 100 épocas\n",
    "scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epocas):  # Número de épocas\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        # Mover datos a GPU\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "        optimizer.zero_grad()\n",
    "        # Calcular pérdida\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "    print(f\"Época {epoch + 1}, Pérdida: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras cosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: {\n",
    "    \"pixel_values\": torch.stack([item[\"pixel_values\"] for item in x]),\n",
    "    \"labels\": [item[\"labels\"] for item in x]  # Lista de diccionarios\n",
    "})\n",
    "for i, datos in enumerate(train_loader):\n",
    "    if i<1:\n",
    "        dp = datos\n",
    "        print(\"Lote de imágenes para entrenamiento:\", datos[\"pixel_values\"].shape)\n",
    "        print(\"Anotaciones:\", datos[\"labels\"])\n",
    "        pixel_values = datos[\"pixel_values\"]\n",
    "        labels = [{k: v for k, v in t.items()} for t in datos[\"labels\"]]\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#with torch.no_grad():\n",
    "outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "loss = outputs.loss\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    pixel_values = batch[\"pixel_values\"]\n",
    "    labels = [{k: v for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
